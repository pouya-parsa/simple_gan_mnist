{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J3c1hltllN3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ02SWplk1Iw"
      },
      "source": [
        "noise_dim = 64\n",
        "batch_size = 128\n",
        "lr = 0.00001\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTGNu0LOq5fP",
        "outputId": "8ce2df84-034d-4087-c105-b32b1a840cc6"
      },
      "source": [
        "train_loader = DataLoader(MNIST(root=\"./content\", download=True, train=True, transform=transforms.ToTensor()), batch_size=batch_size, shuffle=True)\n",
        "len(train_loader)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "469"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vQkg8-YlkAr"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_dim = 128, output_size = 28 * 28):\n",
        "    \n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(noise_dim, hidden_dim),\n",
        "        nn.BatchNorm1d(hidden_dim),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "        nn.BatchNorm1d(hidden_dim * 2),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Linear(hidden_dim * 2, hidden_dim * 4),\n",
        "        nn.BatchNorm1d(hidden_dim * 4),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Linear(hidden_dim * 4, hidden_dim * 8),\n",
        "        nn.BatchNorm1d(hidden_dim * 8),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Linear(hidden_dim * 8, output_size),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gevMsqEnpjW"
      },
      "source": [
        "def get_noise(size, device):\n",
        "  return torch.randn(size, device=device)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oO5P3Nzni-f"
      },
      "source": [
        "noise = get_noise((batch_size, noise_dim), device=device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnkb7vhVn4IB"
      },
      "source": [
        "gen = Generator().to(device)\n",
        "gen_optimizer = torch.optim.Adam(gen.parameters(), lr=lr)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smr--x2HoLfJ"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self, image_size = 784, hidden = 128):\n",
        "    \n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        \n",
        "        nn.Linear(image_size, hidden * 4),\n",
        "        # nn.BatchNorm1d(hidden * 4),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Linear(hidden * 4, hidden * 2),\n",
        "        # nn.BatchNorm1d(hidden * 2),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Linear(hidden * 2, hidden),\n",
        "        # nn.BatchNorm1d(hidden),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Linear(hidden, 1),\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "\n",
        "    return self.model(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TYJdJ2DpzJ7"
      },
      "source": [
        "disc = Discriminator(image_size=784, hidden=128).to(device)\n",
        "disc_optimizer = torch.optim.Adam(disc.parameters(), lr=lr)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-TnaNThp3KG"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNoiKY2oqZhp"
      },
      "source": [
        "def gen_loss(generator, discriminator, real, num_images, z_dim, device):\n",
        "\n",
        "  # real is tensor of shape (batch_size, 28 * 28)\n",
        "  # num_images is the length of real\n",
        "  \n",
        "  noise = get_noise((num_images, z_dim), device)\n",
        "  out_gen = generator(noise)\n",
        "  out_disc = discriminator(out_gen)\n",
        "  \n",
        "  gen_loss = criterion(out_disc, torch.ones_like(out_disc))\n",
        "  \n",
        "  return gen_loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ9nc5NzuJkK"
      },
      "source": [
        "def disc_loss(generator, discriminator, real, num_images, z_dim, device):\n",
        "\n",
        "  # real is tensor of shape (batch_size, 28 * 28)\n",
        "  # num_images is the length of real\n",
        "\n",
        "  noise = get_noise((num_images, z_dim), device)\n",
        "  out_gen_fake = generator(noise).detach()\n",
        "  out_disc_fake = discriminator(out_gen_fake)\n",
        "  fake_loss = criterion(out_disc_fake, torch.zeros_like(out_disc_fake))\n",
        "\n",
        "  out_disc_real = discriminator(real)\n",
        "  real_loss = criterion(out_disc_real, torch.ones_like(out_disc_real))\n",
        "\n",
        "  disc_loss = (1/2) * (fake_loss + real_loss)\n",
        "\n",
        "  return disc_loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqZ0eSeO2gx6"
      },
      "source": [
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "    \n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in a uniform grid.\n",
        "    '''\n",
        "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiBQUmsB5cgR"
      },
      "source": [
        "cur_step = 0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA9aLgxOvhFW"
      },
      "source": [
        "for epoch in range(30):\n",
        "\n",
        "  for iteration, (X, y) in enumerate(train_loader):\n",
        "    \n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    # Training Generator\n",
        "\n",
        "    gen_optimizer.zero_grad()\n",
        "    \n",
        "    gloss = gen_loss(gen, disc, X.reshape(-1, 28 * 28), len(X), noise_dim, device)\n",
        "\n",
        "    gloss.backward()\n",
        "\n",
        "    gen_optimizer.step()\n",
        "\n",
        "\n",
        "    # Training Discriminator\n",
        "\n",
        "    disc_optimizer.zero_grad()\n",
        "\n",
        "    dloss = disc_loss(gen, disc, X.reshape(-1, 28 * 28), len(X), noise_dim, device)\n",
        "\n",
        "    dloss.backward()\n",
        "    \n",
        "    disc_optimizer.step()\n",
        "    \n",
        "\n",
        "    ## Visualize Generator output\n",
        "\n",
        "    if cur_step % 500 == 0:\n",
        "      print(\"Generator Loss : \", gloss.item())\n",
        "      print(\"Discriminator Loss : \", dloss.item())\n",
        "\n",
        "\n",
        "      noise = get_noise((batch_size, noise_dim), device)\n",
        "      out = gen(noise)\n",
        "      print(cur_step)\n",
        "      show_tensor_images(out)\n",
        "      show_tensor_images(X)\n",
        "    \n",
        "    cur_step += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}